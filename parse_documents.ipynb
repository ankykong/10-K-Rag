{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankurduggal/.pyenv/versions/3.11.8/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.readers.google import GoogleDriveReader\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core.node_parser import MarkdownNodeParser, SentenceSplitter\n",
    "from llama_index.core import VectorStoreIndex, QueryBundle, Response, Document, Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.vector_stores.elasticsearch import ElasticsearchStore\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# llm = Cohere(model=\"command-nightly\", api_key=cohere_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = MarkdownNodeParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_keys = os.getenv(\"LLAMA_INDEX_KEYS\").split(',')\n",
    "for i, api_key in enumerate(api_keys[1:]):\n",
    "    api_keys[i+1] = api_key[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "parser = LlamaParse(\n",
    "    api_key=api_keys[0],\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    "    language=\"en\",\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "# loaded_docs = parser.load_data(\"./Data/AMZN/AMZN2019.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_company_folder(company_folder_path):\n",
    "    pdf_paths =[]\n",
    "    for pdf_file in os.listdir(company_folder_path):\n",
    "        pdf_path = os.path.join(company_folder_path, pdf_file)\n",
    "        pdf_paths.append(pdf_path)\n",
    "    for api_key in api_keys:\n",
    "        try:\n",
    "            parser = LlamaParse(\n",
    "                api_key=api_key,\n",
    "                result_type=\"markdown\",\n",
    "                verbose=True,\n",
    "                language=\"en\",\n",
    "                num_workers=2,\n",
    "            )\n",
    "            loaded_docs = parser.load_data(pdf_paths)\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    documents.append(loaded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 34495a19-e5dd-49bc-811b-d1860a020f60\n",
      "Started parsing the file under job_id d07282d7-9580-425e-b3f6-1695c8c239a0\n",
      "Started parsing the file under job_id 082279a2-df43-4a07-b7ad-822893af9d0c\n",
      "Started parsing the file under job_id 4e559d2d-e121-4905-b803-71232ede0d1b\n",
      "Started parsing the file under job_id b863b0f1-f8b4-4507-a06d-61d3558f0212\n",
      "..Started parsing the file under job_id 63f95b71-c110-46ff-b775-72e666fd3e10\n",
      "Started parsing the file under job_id 93b276f0-c399-41c8-ab38-38bfb3434255\n",
      "Started parsing the file under job_id 6e7eaffb-cc42-4ca7-ac81-9c9db82d9c92\n",
      "Started parsing the file under job_id a247f79c-d5c1-4e85-8f90-11ab819c8e0f\n",
      "Started parsing the file under job_id def51d3f-febf-49ef-a488-7a30a480d1e5\n",
      "Started parsing the file under job_id e51c9331-74e2-4e60-be3e-e502ab4dd3f6\n",
      "Started parsing the file under job_id cca32ca2-6f13-4a50-8301-1c8cd9624d34\n",
      "Started parsing the file under job_id 3ee38181-16db-4f4c-80ab-613d0c84ac99\n",
      "Started parsing the file under job_id 70a60f03-e968-4464-ab62-1e0ec2adf7d5\n",
      "Started parsing the file under job_id ee981396-73fb-47ef-b87d-8994c146aba6\n",
      "Started parsing the file under job_id 5eec3369-4475-48aa-9291-7b7ecc1e942b\n",
      "Started parsing the file under job_id 0ae122f2-75a6-437f-aea7-258e8e9530dd\n",
      "Started parsing the file under job_id 949619f5-2085-42bb-b02a-a2a1541a0eca\n",
      "Started parsing the file under job_id 9338b0dc-28f5-430a-9da1-e7f3515f58bf\n",
      "Started parsing the file under job_id b64132f1-5620-4b9a-8e2b-aa79248761d2\n",
      "Started parsing the file under job_id 6609b7b7-076d-4758-85b4-8e43ba4b97b5\n",
      "Started parsing the file under job_id 1e5b7810-9538-4a77-8609-e49d21b6a45f\n",
      "Started parsing the file under job_id cad0701d-84cf-4a43-8590-f0b292cd46b6\n",
      "Started parsing the file under job_id 0aeda5b8-f3b5-4d17-bed3-6b763b4042be\n",
      "Started parsing the file under job_id 301d51e6-09ae-4e14-bea0-4403fdf90bea\n",
      "Started parsing the file under job_id 765d8768-ecd2-42c9-8379-464672782cb1\n",
      "Started parsing the file under job_id 954d4b94-6edd-4b29-871d-6030526e24de\n",
      "Started parsing the file under job_id 10b8e85d-c1cc-43e3-9b6c-3f96501d60d6\n",
      "Started parsing the file under job_id 41cd447c-edaa-4c4e-ac6d-80c5d949d773\n",
      "Started parsing the file under job_id fc29c5ab-7963-4411-bd6d-3c04a8836b44\n",
      "Started parsing the file under job_id 639e6700-e6df-443b-ac28-ae9bfb1bc845\n",
      "Started parsing the file under job_id 9dc9b57a-6ffa-42a8-bbe6-8ab25d89d8d2\n",
      "Started parsing the file under job_id 845933f1-9bad-4984-9090-77b844a2f7c8\n",
      "Started parsing the file under job_id 7a517ba9-69e2-4d3e-a0e8-e7ff5af45b7b\n",
      "Started parsing the file under job_id d278e5d6-4b43-4c11-a8bc-d497a5005c74\n",
      "Started parsing the file under job_id eac95a11-d9b8-475a-9574-39d6a0258686\n",
      "Started parsing the file under job_id 05f56d00-e8c4-4dfa-a3cc-1b6a427653dc\n",
      "Started parsing the file under job_id dd94bd46-b764-4ac4-b150-abad0de7edb5\n",
      "Started parsing the file under job_id ae810ba4-e4b7-4b04-9b97-442238676c89\n",
      "Started parsing the file under job_id 0a6f0e87-6c87-4ad4-98ba-5a408dd71df1\n",
      "Started parsing the file under job_id 67e028d3-8786-49de-b4f3-cfde060b52a1\n",
      "Started parsing the file under job_id b14648db-0098-414b-871e-675dafe76182\n",
      "Started parsing the file under job_id 6fc410d4-bc27-41ec-b0d4-80bf18e4ce49\n",
      "Started parsing the file under job_id 2547a6d9-76c7-4e4c-89d6-cdd645674034\n",
      "Started parsing the file under job_id 6414025c-e81d-4ebf-910a-7e6e8d8978ff\n",
      "Started parsing the file under job_id e16e9786-e9c1-4294-9da1-58a124a0838e\n",
      "Started parsing the file under job_id b1d9358e-6b9d-4422-b515-9cac1fe5907f\n",
      "Started parsing the file under job_id 00114a6b-20c5-4a79-aa48-e4d3a7cdf00d\n",
      "Started parsing the file under job_id 8b48e6f4-9857-470c-a284-01d0ee37d27b\n",
      "Started parsing the file under job_id f51ab88f-3acc-450c-97c3-1ad8d94ee5fc\n"
     ]
    }
   ],
   "source": [
    "# Iterate and process company folders\n",
    "file_path = 'Data'\n",
    "for company in os.listdir(file_path):\n",
    "    if company == '.DS_Store':\n",
    "        continue\n",
    "    company_folder_path = os.path.join(file_path, company)\n",
    "    process_company_folder(company_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_nodes = []\n",
    "for company in documents:\n",
    "    nodes = node_parser.get_nodes_from_documents(company)\n",
    "    company_nodes.append(nodes)\n",
    "\n",
    "company_nodes = [item for company_node in company_nodes for item in company_node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch, Embed, Store/Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELASTIC_CLOUD_ID = os.getenv(\"ELASTIC_CLOUD_ID\")\n",
    "ELASTIC_API_KEY = os.getenv(\"ELASTIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_vector_store = ElasticsearchStore(index_name=\"calls\",\n",
    "                                     vector_field='conversation_vector',\n",
    "                                     text_field='conversation',\n",
    "                                     es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "                                     es_api_key=ELASTIC_API_KEY)\n",
    "\n",
    "ollama_embedding = OllamaEmbedding(\"mistral\")\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=350, chunk_overlap=50),\n",
    "        ollama_embedding,\n",
    "    ],\n",
    "    vector_store=es_vector_store\n",
    ")\n",
    "\n",
    "pipeline.run(documents=company_nodes)\n",
    "print(\".....Done running pipeline.....\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_vector_store = ElasticsearchStore(index_name=\"calls\",\n",
    "                                     vector_field='conversation_vector',\n",
    "                                     text_field='conversation',\n",
    "                                     es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "                                     es_api_key=ELASTIC_API_KEY)\n",
    "\n",
    "ollama_embedding = resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=1000, chunk_overlap=150),\n",
    "        ollama_embedding,\n",
    "    ],\n",
    "    vector_store=es_vector_store\n",
    ")\n",
    "\n",
    "pipeline.run(documents=company_nodes)\n",
    "print(\".....Done running pipeline.....\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Run Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_vector_store = ElasticsearchStore(index_name=\"calls\",\n",
    "                                     vector_field='conversation_vector',\n",
    "                                     text_field='conversation',\n",
    "                                     es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "                                     es_api_key=ELASTIC_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat the original answer since the new context doesn't provide useful information to rewrite an answer. There is no mention of a quarterly cash dividend per share in the provided context information for any quarter, including the second quarter of 2022, for Google or Alphabet Inc. The context only provides financial information and discussions about the company's operations, revenues, and expenses, but does not mention dividends.\n"
     ]
    }
   ],
   "source": [
    "# Local LLM to send user query to\n",
    "local_llm = Ollama(model=\"llama3:instruct\", request_timeout=60.0)\n",
    "Settings.embed_model= resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(es_vector_store)\n",
    "query_engine = index.as_query_engine(local_llm, similarity_top_k=10)\n",
    "\n",
    "query=\"How much was the quarterly cash dividend per share in the second quarter of 2022 for Google\"\n",
    "bundle = QueryBundle(query, embedding=Settings.embed_model.get_query_embedding(query))\n",
    "result = query_engine.query(bundle)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
