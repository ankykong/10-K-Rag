{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.readers.google import GoogleDriveReader\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core.node_parser import MarkdownNodeParser, SentenceSplitter\n",
    "from llama_index.core import VectorStoreIndex, QueryBundle, Response, Document, Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.vector_stores.elasticsearch import ElasticsearchStore\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from dotenv import load_dotenv\n",
    "import cohere\n",
    "import time\n",
    "\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# llm = Cohere(model=\"command-nightly\", api_key=cohere_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = MarkdownNodeParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_keys = os.getenv(\"LLAMA_INDEX_KEYS\").split(',')\n",
    "for i, api_key in enumerate(api_keys[1:]):\n",
    "    api_keys[i+1] = api_key[1:]\n",
    "\n",
    "ELASTIC_CLOUD_ID = os.getenv(\"ELASTIC_CLOUD_ID_MISTRAL\")\n",
    "ELASTIC_API_KEY = os.getenv(\"ELASTIC_API_KEY_MISTRAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "parser = LlamaParse(\n",
    "    api_key=api_keys[0],\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    "    language=\"en\",\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_company_folder(company_folder_path):\n",
    "    pdf_paths =[]\n",
    "    for pdf_file in os.listdir(company_folder_path):\n",
    "        pdf_path = os.path.join(company_folder_path, pdf_file)\n",
    "        pdf_paths.append(pdf_path)\n",
    "    for api_key in api_keys:\n",
    "        try:\n",
    "            parser = LlamaParse(\n",
    "                api_key=api_key,\n",
    "                result_type=\"markdown\",\n",
    "                verbose=True,\n",
    "                language=\"en\",\n",
    "                num_workers=2,\n",
    "            )\n",
    "            loaded_docs = parser.load_data(pdf_paths)\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    documents.append(loaded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id ef4e2720-c747-49a8-a87e-85c0399d86e0\n",
      "Started parsing the file under job_id f6254d11-550e-4ab9-9e53-9fb44d75b33f\n",
      "Started parsing the file under job_id a75fee58-b28d-4e3b-bc1a-6e995b5ca207\n",
      "Started parsing the file under job_id 83521b96-b930-46b5-a8a1-cba477dd03ee\n",
      "Started parsing the file under job_id 5be70019-1e15-41ef-8459-fe340fb87a1f\n",
      "Started parsing the file under job_id 6efc1447-3e07-451d-b323-581e1633a87c\n",
      "Started parsing the file under job_id e4d071f5-f748-4e1b-921c-fe418f5ef430\n",
      "Started parsing the file under job_id 19e4fc23-ac35-4895-9ce0-8daaeb4149e4\n",
      "Started parsing the file under job_id feb3217a-653c-4c1e-8251-4be11a7cc685\n",
      "Started parsing the file under job_id a1dbb77a-bd61-494e-89e2-c9680f406b96\n",
      "Started parsing the file under job_id a413d236-ca26-4da2-86c2-da6582461c16\n",
      "Started parsing the file under job_id edaa9987-6f65-47a7-9788-857a7c254b79\n",
      "Started parsing the file under job_id b8a64871-ec3e-4317-a16b-e4c1e1a2547e\n",
      "Started parsing the file under job_id 1a901404-efdd-4e3e-a8d2-72cd58de5bb7\n",
      "Started parsing the file under job_id c1660bea-25e1-4eb2-9ee0-2e95ebed0e6f\n",
      "Started parsing the file under job_id 09a632c2-aa01-4a37-84f4-89eb0988de97\n",
      "Started parsing the file under job_id 269bf8e6-599a-4902-8c66-86bf5f4a09fe\n",
      "Started parsing the file under job_id 5d63f0cb-35d6-4218-8ce4-c4f3461d9cdc\n",
      "Started parsing the file under job_id 37282b13-4af9-4f1f-a949-c696a17f14bc\n",
      "Started parsing the file under job_id 75ac7e5b-4572-4d37-a64d-cb61f13737dc\n",
      "Started parsing the file under job_id ea2998e1-08a9-4f1a-9f77-e692a9cbfb2a\n",
      "Started parsing the file under job_id 106e2988-12b9-4871-8342-797333cc10c9\n",
      "Started parsing the file under job_id 5436ae47-fb28-47a8-bf2c-2a4096d038bf\n",
      "Started parsing the file under job_id 9c7d3e10-fc03-4034-836e-1005ebf31612\n",
      "Started parsing the file under job_id aae26239-c5d1-4dca-be32-b0d2e9f18ee1\n",
      "Started parsing the file under job_id a55b6f15-80ca-4e34-bc92-43cda05102ff\n",
      "Started parsing the file under job_id 31234400-d774-4d1b-87ab-bd936696aba5\n",
      "Started parsing the file under job_id d58fbd49-c741-4bd8-b25a-4d615e0429ff\n",
      "Started parsing the file under job_id b35fafdc-0ad0-4420-8fba-bcdc23c6b853\n",
      "Started parsing the file under job_id 1eadcfa3-dc46-488b-9a2c-0913a9a1df5d\n",
      "Started parsing the file under job_id 742e02f2-52d4-4c1d-b571-dde79ac0ac34\n",
      "Started parsing the file under job_id 6bc356bd-6f04-4441-8cd5-b1aa5fd311c7\n",
      "Started parsing the file under job_id d91ac09e-c736-4213-8bb4-fe653b1fe7d9\n",
      "Started parsing the file under job_id fb59ee58-c06f-42d6-bdd2-90d2cb5ce3b5\n",
      "Started parsing the file under job_id 854ac259-d447-4949-aae9-2654240db252\n",
      "Started parsing the file under job_id 82623ce0-d907-4d3d-9578-e4e986c50f35\n",
      "Started parsing the file under job_id 5963b94a-da44-40f2-8488-c198df056523\n",
      "Started parsing the file under job_id 5b2b593b-8d19-46ba-9a56-b23ae08300c1\n",
      "Started parsing the file under job_id 8176d498-cb2f-49b6-ba38-fbf5a627f4ae\n",
      "Started parsing the file under job_id 432ed3ce-a900-4592-91a2-613dd1a77117\n",
      "Started parsing the file under job_id 4b131890-f186-43ce-871a-3af369b47881\n",
      "Started parsing the file under job_id 56c96426-5534-43e5-b1b4-10aac796aa24\n",
      "Started parsing the file under job_id 7b1eb46a-d7de-46f6-89a2-f10fe4c4a2c1\n",
      "Started parsing the file under job_id 56908d13-f902-495c-b5cd-9132c2309efa\n",
      "Started parsing the file under job_id 49f7cc68-96c0-41cd-85b9-17c0f999b26b\n",
      "Started parsing the file under job_id a1206122-e5ee-4c5f-8235-c186484677e2\n",
      "Started parsing the file under job_id 45ec1404-711c-4442-a03c-b2682e3f0e50\n",
      "Started parsing the file under job_id c2e65624-8d19-45f3-bf33-b45fc316ee94\n",
      "Started parsing the file under job_id cd24966a-d77e-4bb4-968e-92117c208e7c\n",
      "Started parsing the file under job_id 30553913-08d2-4ae6-ba0a-6d5f6e48a51c\n"
     ]
    }
   ],
   "source": [
    "# Iterate and process company folders\n",
    "file_path = 'Data'\n",
    "for company in os.listdir(file_path):\n",
    "    if company == '.DS_Store':\n",
    "        continue\n",
    "    company_folder_path = os.path.join(file_path, company)\n",
    "    process_company_folder(company_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_nodes = []\n",
    "for company in documents:\n",
    "    nodes = node_parser.get_nodes_from_documents(company)\n",
    "    company_nodes.append(nodes)\n",
    "\n",
    "company_nodes = [item for company_node in company_nodes for item in company_node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch, Embed, Store/Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELASTIC_CLOUD_ID=\"Nlp_project:\"+ELASTIC_CLOUD_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_vector_store = ElasticsearchStore(index_name=\"calls\",\n",
    "                                     vector_field='conversation_vector',\n",
    "                                     text_field='conversation',\n",
    "                                     es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "                                     es_api_key=ELASTIC_API_KEY)\n",
    "\n",
    "embed_model = resolve_embed_model(\"local:BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=1000, chunk_overlap=150),\n",
    "        embed_model,\n",
    "    ],\n",
    "    vector_store=es_vector_store\n",
    ")\n",
    "\n",
    "pipeline.run(documents=company_nodes)\n",
    "print(\".....Done running pipeline.....\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_vector_store = ElasticsearchStore(index_name=\"calls\",\n",
    "                                     vector_field='conversation_vector',\n",
    "                                     text_field='conversation',\n",
    "                                     es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "                                     es_api_key=ELASTIC_API_KEY)\n",
    "\n",
    "ollama_embedding = resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=1000, chunk_overlap=150),\n",
    "        ollama_embedding,\n",
    "    ],\n",
    "    vector_store=es_vector_store\n",
    ")\n",
    "\n",
    "pipeline.run(documents=company_nodes)\n",
    "print(\".....Done running pipeline.....\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Run Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_vector_store = ElasticsearchStore(index_name=\"calls\",\n",
    "                                     vector_field='conversation_vector',\n",
    "                                     text_field='conversation',\n",
    "                                     es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "                                     es_api_key=ELASTIC_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'COHERE_API_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m co \u001b[38;5;241m=\u001b[39m cohere\u001b[38;5;241m.\u001b[39mClient(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOHERE_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      3\u001b[0m documents \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Example query and passages\u001b[39;00m\n",
      "File \u001b[0;32m<frozen os>:679\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'COHERE_API_KEY'"
     ]
    }
   ],
   "source": [
    "co = cohere.Client(os.environ[\"COHERE_API_KEY\"])\n",
    "\n",
    "query=\"How much was the quarterly cash dividend per share in the second quarter of 2022 for Google\"\n",
    "\n",
    "documents = [doc.page_content for doc in docs]\n",
    "\n",
    "# Example query and passages\n",
    "start = time.time()\n",
    "\n",
    "results = co.rerank(query=query, documents=documents, top_n=4, model=\"rerank-english-v2.0\")\n",
    "print(f\"Took {time.time() - start} seconds to re-rank documents with Cohere.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat the original answer since the new context doesn't provide useful information to rewrite an answer. There is no mention of a quarterly cash dividend per share in the provided context information for any quarter, including the second quarter of 2022, for Google or Alphabet Inc. The context only provides financial information and discussions about the company's operations, revenues, and expenses, but does not mention dividends.\n"
     ]
    }
   ],
   "source": [
    "# Local LLM to send user query to\n",
    "local_llm = Ollama(model=\"llama3:instruct\", request_timeout=60.0)\n",
    "Settings.embed_model= resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(es_vector_store)\n",
    "query_engine = index.as_query_engine(local_llm, similarity_top_k=10)\n",
    "\n",
    "query=\"How much was the quarterly cash dividend per share in the second quarter of 2022 for Google\"\n",
    "bundle = QueryBundle(query, embedding=Settings.embed_model.get_query_embedding(query))\n",
    "result = query_engine.query(bundle)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
